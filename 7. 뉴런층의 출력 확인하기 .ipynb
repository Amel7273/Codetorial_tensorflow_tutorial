{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMFKDZ5uNrSCBi/3V4jyhaq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 7. 뉴런층의 출력 확인하기"],"metadata":{"id":"dT6_OoepWQKq"}},{"cell_type":"markdown","source":["<img src=\"https://codetorial.net/tensorflow/_images/get_output_of_neuron_layers_0.png\"/>"],"metadata":{"id":"oozrzn04WV78"}},{"cell_type":"markdown","source":["이전 페이지에서 각 뉴런츠으이 이름, 자료형, 활성화함수와 같은 다양한 정보를 확인하는 방법에 대해 알아보았습니다.\n","\n","이 페이지에서는 특정 입력 데이터에 대해 각 뉴런층이 출력하는 값을 확인하는 방법에 대해 소개합니다."],"metadata":{"id":"NWDlIkk2WbwC"}},{"cell_type":"markdown","source":["## 예제"],"metadata":{"id":"FPrWxNqYU8Kb"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# 1. MNIST 데이터셋 임포트\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# 2. 데이터 전처리\n","x_train, x_test = x_train/255.0, x_test/255.0\n","\n","# 3. 모델 구성\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Flatten(input_shape=(28, 28)),\n","    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])\n","\n","# 4. 모델 컴파일\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# 5. 모델 훈련\n","model.fit(x_train, y_train, epochs=5)\n","\n","# 6. 정확도 평가\n","test_loss, test_acc = model.evaluate(x_test, y_test)\n","print('테스트 정확도:', test_acc)\n"],"metadata":{"id":"uYuWnyS8U9rC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 설명"],"metadata":{"id":"qYgR65D8W75R"}},{"cell_type":"markdown","source":["### 0. tensorflow 불러오기"],"metadata":{"id":"ckPXaLlGVbwj"}},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"OsaEAELEJIEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1. MNIST 데이터셋 임포트"],"metadata":{"id":"UsURfRUkVhf_"}},{"cell_type":"code","source":["mnist = tf.keras.datasets.mnist \n","(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"metadata":{"id":"MncA6oitWVh1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["tensorflow에서 직접 MNIST 손글씨 이미지 데이터셋을 불러와서 사용합니다.\n","\n","load_data() 함수는 x_train, y_train, x_test, y_test 네 개의 NumPy 어레이를 반환합니다.\n","\n","x_train, x_test는 28×28 픽셀의 각 손글씨 이미지 데이터이고, y_train, y_test는 분류에 사용되는 0~9 사이의 레이블 값을 갖습니다.\n","\n","\n"],"metadata":{"id":"RoteCv4PXS4D"}},{"cell_type":"markdown","source":["### 2. 데이터 전처리"],"metadata":{"id":"9zFxFXpWXhj5"}},{"cell_type":"code","source":["x_train, x_test = x_train/255.0, x_test/255.0"],"metadata":{"id":"LTEFZli8XR8z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["0 ~ 255.0 사이의 값을 갖는 픽셀값들을 0 ~ 1.0 사이의 값을 갖도록 변환합니다."],"metadata":{"id":"gB6GT53uWJiy"}},{"cell_type":"markdown","source":["### 3. 모델 구성"],"metadata":{"id":"_gl5FNQwYXH8"}},{"cell_type":"code","source":["# 3. 모델 구성하기\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Flatten(input_shape=(28, 28)),\n","    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])"],"metadata":{"id":"yZBa92YaX6Jg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["tf.keras.models.Sequential()을 이용해서 인공신경망 모델을 구성합니다.\n","\n","입력층 (Input layer)에서 Flatten()을 이용해서 28×28 픽셀의 값을 784개의 1차원 배열로 변환합니다.\n","\n","다음 두 개의 뉴런 층 (Neuron layer)은 Dense()를 이용해서 완전 연결된 층 (Fully-connected layer)를 구성합니다.\n","\n","각 층은 512개와 10개의 인공 뉴런 노드를 갖고 활성화 함수 (activation function)로는 각각 ReLU (tf.nn.relu)와 소프트맥스 (tf.nn.softmax)를 사용합니다."],"metadata":{"id":"ApyYhTIvYigT"}},{"cell_type":"markdown","source":["### 4. 모델 컴파일"],"metadata":{"id":"Rtakb-3_YrOS"}},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n"],"metadata":{"id":"V1-8GVvBYhP9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["다음은 모델 컴파일 단계입니다. 학습 과정에서 손실 함수 (Loss function)를 줄이기 위해 사용되는 optimizer로는 Adam (Adaptive Momentum estimation)을 사용합니다.\n","\n","손실 함수는 ‘sparse_categorical_crossentropy’를 지정하고, 평가 지표로는 정확도 (accuracy)를 사용합니다.\n","\n","정확도는 테스트 이미지 중 올바르게 분류한 비율을 의미합니다.\n","\n"],"metadata":{"id":"WFejJic-ZHPE"}},{"cell_type":"markdown","source":["### 5. 모델 훈련"],"metadata":{"id":"sO9nvHKQZQhU"}},{"cell_type":"code","source":["model.fit(x_train, y_train, epochs=5)"],"metadata":{"id":"uXRy8QYmW2Gk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["model.fit() 메서드에 학습 데이터와, 레이블, 에포크를 순서대로 입력하면, 학습이 이루어집니다.\n","\n","에포크(epoch)는 60,000개의 전체 학습 데이터를 몇 번 반복해서 학습할지를 의미합니다.\n","\n"],"metadata":{"id":"-n5nDj_JXAgp"}},{"cell_type":"markdown","source":["### 6. 정확도 평가"],"metadata":{"id":"V-Ji1FqgbeXA"}},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(x_test, y_test)\n","print('테스트 정확도:', test_acc)"],"metadata":{"id":"XLV7ZkQGbSpS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["전체 신경망의 출력값은 Model 클래스의 predict() 메서드를 사용해서 간단하게 얻을 수 있습니다.\n","\n","세 개의 값을 갖는 세 개의 입력 데이터 벡터에 대해 두 개의 값을 갖는 벡터 세 개를 출력합니다.\n","\n"],"metadata":{"id":"amSABJZuce9z"}},{"cell_type":"markdown","source":["## 전체 예제 코드\n","\n","전체 코드는 아래와 같습니다."],"metadata":{"id":"KwGr30t6crdA"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","tf.random.set_seed(0)\n","\n","\n","# 1. 훈련 데이터 준비하기\n","x_train = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n","y_train = np.array([[0], [1], [1]])\n","\n","\n","# 2. 뉴런층 만들기\n","input_layer = tf.keras.layers.InputLayer(input_shape=(3,))\n","hidden_layer = tf.keras.layers.Dense(units=4, activation='relu')\n","output_layer = tf.keras.layers.Dense(units=2, activation='softmax')\n","\n","\n","# 3. 모델 구성하기\n","model = tf.keras.Sequential([\n","  input_layer,\n","  hidden_layer,\n","  output_layer\n","  ])\n","\n","# 4. 모델 컴파일하기\n","model.compile(loss='mse', optimizer='Adam')\n","\n","\n","# 5. 은닉층의 출력 확인하기\n","intermediate_layer_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n","intermediate_output = intermediate_layer_model(x_train)\n","\n","print('======== Inputs ========')\n","print(x_train)\n","\n","print('\\n======== Weights of Hidden Layer ========')\n","print(hidden_layer.get_weights()[0])\n","\n","print('\\n======== Outputs of Hidden Layer ========')\n","print(intermediate_output)\n","\n","# 6. 출력층의 출력 확인하기\n","pred = model.predict(x_train)\n","\n","print('\\n======== Outputs of Output Layer ========')\n","print(pred)  "],"metadata":{"id":"ehPEE4KZZu3_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KnRH9EBrZGaw"},"execution_count":null,"outputs":[]}]}