{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM3jlTCVJ/QnFbGyBhWiuFk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 6. 뉴런층의 속성 확인하기"],"metadata":{"id":"jVUawJnfLjHd"}},{"cell_type":"markdown","source":["<img src=\"https://codetorial.net/tensorflow/_images/get_attribute_of_neuron_layers_0.png\"/>"],"metadata":{"id":"Vo432oCBLnj1"}},{"cell_type":"markdown","source":["tf.keras.layers.Layer는 Neural Network의 모든 레이어 객체가 상속하는 클래스입니다.\n","\n","tf.keras.layers.Layer의 다양한 속성(Attribute)을 이용해서 각 레이어에 대한 정보를 확인할 수 있습니다."],"metadata":{"id":"jshH7vGqLq09"}},{"cell_type":"markdown","source":["## Table of Contents\n","\n","1. 뉴런층의 이름(name)과 자료형(dtype)\n","2. 뉴런층의 입력(input)과 출력(output)\n","3. 뉴런층의 활성화함수(activation)\n","4. 뉴런층의 가중치(weights)\n","5. get_weights() 메서드"],"metadata":{"id":"wfXJcWmjL9j9"}},{"cell_type":"markdown","source":["## 1) 뉴런층의 이름(name)과 자료형(dtype)"],"metadata":{"id":"NJJoyYLwML_r"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","tf.random.set_seed(0)\n","\n","\n","# 1. 뉴런층 만들기\n","input_layer = tf.keras.layers.InputLayer(input_shape=(3,))\n","hidden_layer = tf.keras.layers.Dense(units=4, activation='relu')\n","output_layer = tf.keras.layers.Dense(units=2, activation='softmax')\n","\n","\n","# 2. 모델 구성하기\n","model = tf.keras.Sequential([\n","    input_layer,\n","    hidden_layer,\n","    output_layer\n","    ])\n","\n","\n","# 3. 모델 컴파일하기\n","model.compile(loss='mse', optimizer='Adam')\n","\n","\n","# 4. 뉴런층의 이름과 자료형\n","print(input_layer.name, input_layer.dtype)\n","print(hidden_layer.name, hidden_layer.dtype)\n","print(output_layer.name, output_layer.dtype)\n"],"metadata":{"id":"mLVn2S18LilI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["name은 뉴런층의 이름입니다.\n","\n","dtype은 뉴런층의 연산과 웨이트 값에 사용되는 자료형입니다.\n","\n","아래와 같은 방법으로도 뉴런층의 속성을 확인할 수 있습니다."],"metadata":{"id":"n8u2b2A4N4nM"}},{"cell_type":"code","source":["print(model.layers[0].name)\n","print(model.layers[1].name)\n","print(model.layers[2].name)"],"metadata":{"id":"um3wRyT7N4bd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["model.layers는 구성한 Neural Network 모델의 (입력층을 제외한) 뉴런층 레이어 객체를 리스트의 형태로 변환합니다.\n","\n","<img src=\"https://codetorial.net/tensorflow/_images/get_attribute_of_neuron_layers_1.png\"/>"],"metadata":{"id":"BtqGfq-oOWEo"}},{"cell_type":"markdown","source":["model.layers[0]은 모델의 첫 번째 뉴런층, 즉 은닉층(hidden layer)입니다.\n","\n","model.layers[1]은 모델의 두 번째 뉴런층, 즉 출력층(output layer)입니다.\n","\n","모델이 (입력층을 제외한) 두 개의 뉴런층을 포함하기 때문에\n","\n","model.layers[2].name을 출력하면 에러가 발생합니다."],"metadata":{"id":"-yqiBgiwPEzX"}},{"cell_type":"markdown","source":["## 2) 뉴런층의 입력(input)과 출력"],"metadata":{"id":"f-_9s_xNPaB_"}},{"cell_type":"code","source":["print(input_layer.input)\n","print(input_layer.output)\n","print()\n","\n","print(hidden_layer.input)\n","print(hidden_layer.output)\n","print()\n","\n","print(hidden_layer.input.shape)\n","print(hidden_layer.output.shape)\n","print()\n","\n","print(output_layer.input)\n","print(output_layer.output)"],"metadata":{"id":"kg3nyPOLPEmV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["input은 뉴런층의 입력 텐서(input tensor)입니다.\n","\n","ouput은 뉴런층의 출력 텐서(output tensor)입니다.\n","\n","은닉층(hidden_layer)의 입력과 출력의 형태(shape)을 출력해보면\n","\n","입력 텐서는 길이 3의 형태, 출력 텐서는 길이 4의 형태를 가짐을 알 수 있습니다.\n","\n","예를 들어, (None,3)은 길이 3의 벡터의 시퀸스 형태가 될 수 있음을 의미합니다."],"metadata":{"id":"nBsQVZjAUUdG"}},{"cell_type":"markdown","source":["3) 뉴런층의 활성화함수 (activation)"],"metadata":{"id":"0bC6BMl_UzNi"}},{"cell_type":"code","source":["print(hidden_layer.activation)\n","print(hidden_layer.activation.__name__)\n","\n","print(output_layer.activation)\n","print(output_layer.activation.__name__)"],"metadata":{"id":"JzmDc69cOVHt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["activation은 뉴런 노드의 활성화함수(Activation Function)을 나타냅니다.\n","\n","__name__을 사용해서 활성화함수의 이름을 출력했습니다."],"metadata":{"id":"udnHgySpVIzk"}},{"cell_type":"markdown","source":["<img src=\"https://codetorial.net/tensorflow/_images/get_attribute_of_neuron_layers_2.png\"/>"],"metadata":{"id":"ksl63rmXVSGU"}},{"cell_type":"markdown","source":["## 4) 뉴런층의 가중치(weights)"],"metadata":{"id":"ToT2Io4_VV7H"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7CN3wP9cLZrb"},"outputs":[],"source":["print(hidden_layer.weights)\n","print(output_layer.weights)"]},{"cell_type":"markdown","source":["weights를 사용해서 각 뉴런층의 시냅스 가중치에 대한 정보를 얻을 수 있습니다."],"metadata":{"id":"BWlc5NeRVgi0"}},{"cell_type":"markdown","source":["<img src = \"https://codetorial.net/tensorflow/_images/get_attribute_of_neuron_layers_3.png\"/>"],"metadata":{"id":"7XtTwuPpVsrl"}},{"cell_type":"markdown","source":["## 5) get_weights() 메서드"],"metadata":{"id":"SU6wZe47VwtL"}},{"cell_type":"code","source":["print(hidden_layer.get_weights()) \n","print(output_layer.get_weights())"],"metadata":{"id":"_tQkyDheVsfG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["get_weights() 메서드를 사용하면 시냅스 가중치를 Numpy 어레이 형태로 얻을 수 있습니다."],"metadata":{"id":"QrGtZW1TV64-"}},{"cell_type":"code","source":[],"metadata":{"id":"Q2RVy43HVcSr"},"execution_count":null,"outputs":[]}]}